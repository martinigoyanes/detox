# Detoxification
Detoxification is an automatic transformation of a text such that:
- text becomes non-toxic
- the content of the text stays the same.

This repository contains the code and data for the paper "Text Detoxification using Large Pre-trained Neural Models".

We suggest two models:
- **CondBERT** --- a BERT-based model which identifies toxic words in a text and replaces them with neutral synonyms
- **ParaGeDi** --- a paraphraser-based model which re-generates a text

## CondBERT

More details

## ParaGeDi

More details

## Parallel detoxification corpus

More details

## Citation

If you use our models or data, please cite the paper:
